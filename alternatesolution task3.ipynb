{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4536a1ea",
   "metadata": {},
   "source": [
    "# ALTERNATE SOLUTION CORRECT OF TASK 3 USINFG DATASET CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8936e43a",
   "metadata": {},
   "source": [
    "# use of canny edge detection, Gradient Orientation Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2102dc1f",
   "metadata": {},
   "source": [
    "# use of R-Table Construction,Generalized Hough Transform,Multi-Scale and Shift Detection,Image Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d15c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from skimage.feature import canny\n",
    "from scipy.ndimage import sobel\n",
    "\n",
    "# Constants for edge detection\n",
    "MIN_CANNY_THRESHOLD = 1\n",
    "MAX_CANNY_THRESHOLD = 400\n",
    "\n",
    "def generate_shifts(max_shift):\n",
    "    shifts = []\n",
    "    for shift_y in range(-max_shift, max_shift + 1):\n",
    "        for shift_x in range(-max_shift, max_shift + 1):\n",
    "            shifts.append((shift_y, shift_x))\n",
    "    return shifts\n",
    "\n",
    "def read_csv_as_paths(csv_path):\n",
    "    np_paths = np.genfromtxt(csv_path, delimiter=',')\n",
    "    paths = []\n",
    "    for i in np.unique(np_paths[:, 0]):\n",
    "        np_points = np_paths[np_paths[:, 0] == i][:, 1:]\n",
    "        path = []\n",
    "        for j in np.unique(np_points[:, 0]):\n",
    "            points = np_points[np_points[:, 0] == j][:, 1:]\n",
    "            path.append(points)\n",
    "        paths.append(path)\n",
    "    return paths\n",
    "\n",
    "def compute_gradient_orientation(image):\n",
    "    dx = sobel(image, axis=0, mode='constant')\n",
    "    dy = sobel(image, axis=1, mode='constant')\n",
    "    gradient = np.arctan2(dy, dx) * 180 / np.pi\n",
    "    return gradient\n",
    "\n",
    "def build_r_table(image, origin):\n",
    "    edges = canny(image, low_threshold=MIN_CANNY_THRESHOLD,\n",
    "                  high_threshold=MAX_CANNY_THRESHOLD)\n",
    "    gradient = compute_gradient_orientation(edges)\n",
    "\n",
    "    r_table = defaultdict(list)\n",
    "    for (i, j), value in np.ndenumerate(edges):\n",
    "        if value:\n",
    "            r_table[gradient[i, j]].append((origin[0] - i, origin[1] - j))\n",
    "    return r_table\n",
    "\n",
    "def accumulate_gradients(r_table, image):\n",
    "    edges = canny(image, low_threshold=MIN_CANNY_THRESHOLD,\n",
    "                  high_threshold=MAX_CANNY_THRESHOLD)\n",
    "    gradient = compute_gradient_orientation(edges)\n",
    "\n",
    "    accumulator = np.zeros(image.shape)\n",
    "    for (i, j), value in np.ndenumerate(edges):\n",
    "        if value:\n",
    "            for r in r_table[gradient[i, j]]:\n",
    "                accum_i, accum_j = i + r[0], j + r[1]\n",
    "                if 0 <= accum_i < accumulator.shape[0] and 0 <= accum_j < accumulator.shape[1]:\n",
    "                    accumulator[accum_i, accum_j] += 1\n",
    "    return accumulator\n",
    "\n",
    "def general_hough_transform(reference_image):\n",
    "    reference_point = (\n",
    "        reference_image.shape[0] // 2, reference_image.shape[1] // 2)\n",
    "    r_table = build_r_table(reference_image, reference_point)\n",
    "\n",
    "    def transform(query_image):\n",
    "        return accumulate_gradients(r_table, query_image)\n",
    "\n",
    "    return transform\n",
    "\n",
    "def find_best_match(reference_images, query_image, scales, shifts):\n",
    "    best_accumulator = None\n",
    "    best_position = None\n",
    "    best_scale = 1\n",
    "    best_shift = (0, 0)\n",
    "    best_reference_image = None\n",
    "    max_accumulator_value = 0\n",
    "\n",
    "    for reference_image in reference_images:\n",
    "        for scale in scales:\n",
    "            scaled_reference_image = cv2.resize(\n",
    "                reference_image, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            hough_transform = general_hough_transform(scaled_reference_image)\n",
    "            accumulator = hough_transform(query_image)\n",
    "\n",
    "            for shift_y, shift_x in shifts:\n",
    "                shifted_accumulator = np.roll(accumulator, shift=(shift_y, shift_x), axis=(0, 1))\n",
    "                max_value = shifted_accumulator.max()\n",
    "\n",
    "                if max_value >= max_accumulator_value:\n",
    "                    max_accumulator_value = max_value\n",
    "                    best_accumulator = shifted_accumulator\n",
    "                    best_position = np.unravel_index(shifted_accumulator.argmax(), shifted_accumulator.shape)\n",
    "                    best_scale = scale\n",
    "                    best_shift = (shift_y, shift_x)\n",
    "                    best_reference_image = scaled_reference_image\n",
    "\n",
    "    return best_position, best_scale, best_shift, best_reference_image\n",
    "\n",
    "def overlay_reference(query_image, reference_image, position):\n",
    "    ref_h, ref_w = reference_image.shape\n",
    "    q_h, q_w = query_image.shape\n",
    "\n",
    "    ref_h_half = ref_h // 2\n",
    "    ref_w_half = ref_w // 2\n",
    "\n",
    "    pos_y, pos_x = position\n",
    "    start_y = max(0, pos_y - ref_h_half)\n",
    "    start_x = max(0, pos_x - ref_w_half)\n",
    "    end_y = min(q_h, pos_y + ref_h_half)\n",
    "    end_x = min(q_w, pos_x + ref_w_half)\n",
    "\n",
    "    ref_start_y = ref_h_half - (pos_y - start_y)\n",
    "    ref_start_x = ref_w_half - (pos_x - start_x)\n",
    "    ref_end_y = ref_start_y + (end_y - start_y)\n",
    "    ref_end_x = ref_start_x + (end_x - start_x)\n",
    "\n",
    "    query_image[start_y:end_y, start_x:end_x] = np.maximum(\n",
    "        query_image[start_y:end_y, start_x:end_x],\n",
    "        reference_image[ref_start_y:ref_end_y, ref_start_x:ref_end_x]\n",
    "    )\n",
    "\n",
    "    return query_image\n",
    "\n",
    "def detect_shape(reference_images, query_image):\n",
    "    scales = [1.0]\n",
    "    shifts = [(0, 0)]\n",
    "\n",
    "    best_position, best_scale, best_shift, best_reference_image = find_best_match(\n",
    "        reference_images, query_image, scales, shifts)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.gray()\n",
    "\n",
    "    plt.title('Original Query Image')\n",
    "    plt.imshow(query_image, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    if best_position and best_reference_image is not None:\n",
    "        scaled_reference_image = cv2.resize(\n",
    "            best_reference_image, None, fx=best_scale, fy=best_scale, interpolation=cv2.INTER_LINEAR)\n",
    "        shifted_position = (best_position[0] + best_shift[0], best_position[1] + best_shift[1])\n",
    "        final_image = overlay_reference(query_image.copy(), scaled_reference_image, shifted_position)\n",
    "\n",
    "        plt.title('Final Image with Detected Shape')\n",
    "        plt.imshow(final_image, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "def shapes_to_image(shape_paths, image_shape=(250, 250)):\n",
    "    image = np.zeros(image_shape, dtype=np.uint8)\n",
    "    for shape in shape_paths:\n",
    "        for points in shape:\n",
    "            for x, y in points:\n",
    "                image[int(y), int(x)] = 255\n",
    "    return image\n",
    "\n",
    "def test_shape_detection():\n",
    "    reference_shapes_list = [\n",
    "        read_csv_as_paths(r\"C:\\Users\\arush\\Downloads\\single_ellipse.csv\"),\n",
    "        read_csv_as_paths(r\"C:\\Users\\arush\\Downloads\\double_ellipse.csv\")\n",
    "    ]\n",
    "    query_shapes = read_csv_as_paths(r\"C:\\Users\\arush\\OneDrive\\Documents\\problems\\occlusion2.csv\")\n",
    "\n",
    "    reference_images = [shapes_to_image(shapes) for shapes in reference_shapes_list]\n",
    "    query_image = shapes_to_image(query_shapes)\n",
    "\n",
    "    detect_shape(reference_images, query_image)\n",
    "\n",
    "def test_another_shape_detection():\n",
    "    reference_shapes_list = [\n",
    "        read_csv_as_paths(r\"C:\\Users\\arush\\Downloads\\single_ellipse.csv\"),\n",
    "        read_csv_as_paths(r\"C:\\Users\\arush\\Downloads\\double_ellipse.csv\")\n",
    "    ]\n",
    "    query_shapes = read_csv_as_paths(r\"C:\\Users\\arush\\OneDrive\\Documents\\problems\\occlusion1.csv\")\n",
    "\n",
    "    reference_images = [shapes_to_image(shapes) for shapes in reference_shapes_list]\n",
    "    query_image = shapes_to_image(query_shapes)\n",
    "\n",
    "    detect_shape(reference_images, query_image)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_shape_detection()\n",
    "    test_another_shape_detection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e57aab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
